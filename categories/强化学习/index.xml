<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>强化学习 - 分类 - SivanLaai's Blog</title><link>https://blog.laais.cn/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</link><description>强化学习 - 分类 - SivanLaai's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>lyhhap@163.com (SivanLaai)</managingEditor><webMaster>lyhhap@163.com (SivanLaai)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 28 Sep 2023 11:52:17 +0800</lastBuildDate><atom:link href="https://blog.laais.cn/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="self" type="application/rss+xml"/><item><title>Q学习算法</title><link>https://blog.laais.cn/posts/learning/rl/q_learning/</link><pubDate>Thu, 28 Sep 2023 11:52:17 +0800</pubDate><author>SivanLaai</author><guid>https://blog.laais.cn/posts/learning/rl/q_learning/</guid><description>on-policy version off-policy version 算法实现 Value update 需要使用behaviour进采行采样 每一个episode里面会对所有的样本行采样来计算$y_T$，这个是target网络</description></item><item><title>简介</title><link>https://blog.laais.cn/posts/learning/rl/rl_basic/</link><pubDate>Thu, 28 Sep 2023 10:36:03 +0800</pubDate><author>SivanLaai</author><guid>https://blog.laais.cn/posts/learning/rl/rl_basic/</guid><description>概念 原先的动作是没有标签的，强化学习可以对每一个动作进行打分，然后学习，不断的迭代完成算法的学习。 按环境分类 Model-Free RL（不理解所处环境） 环境给到</description></item></channel></rss>